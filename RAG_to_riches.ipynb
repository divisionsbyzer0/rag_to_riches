{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e72dca-5af6-49d6-839f-ee1cb999efea",
   "metadata": {},
   "source": [
    "# RAG to Riches\n",
    "In this notebook we will apply retrieval-augmented generation (RAG) to the ultimate redemption story (atleast that is available in the public domain) _The Count of Monte Cristo_. He we will leverage two ollama models, `nomic-embed-text` for embedding text and `mistral` for the chat bot. Make sure you have these installed as well as the dependencies below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda7c1fc-cec1-438b-b513-42d51ca5deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5696d8-3481-4517-a793-b90a4192f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the text\n",
    "\n",
    "url_res = requests.get(url= \"https://www.gutenberg.org/cache/epub/1184/pg1184.txt\")\n",
    "fname = 'the_count_of_monte_cristo.txt'\n",
    "with open(fname, \"wb\") as f:\n",
    "    f.write(url_res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9a1f26-3d83-4122-a1fc-eeded517e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['possibly be the case, I confess; but if such persons are among my\\n', 'acquaintances I prefer not to know it, because then I should be forced\\n', 'to hate them.”\\n', '\\n', '“You are wrong; you should always strive to see clearly around you. You\\n', 'seem a worthy young man; I will depart from the strict line of my duty\\n', 'to aid you in discovering the author of this accusation. Here is the\\n', 'paper; do you know the writing?” As he spoke, Villefort drew the letter\\n', 'from his pocket, and presented it to Dantès. Dantès read it. A cloud\\n', 'passed over his brow as he said:\\n', '\\n', '“No, monsieur, I do not know the writing, and yet it is tolerably\\n', 'plain. Whoever did it writes well. I am very fortunate,” added he,\\n', 'looking gratefully at Villefort, “to be examined by such a man as you;\\n', 'for this envious person is a real enemy.” And by the rapid glance that\\n', 'the young man’s eyes shot forth, Villefort saw how much energy lay hid\\n', 'beneath this mildness.\\n', '\\n', '“Now,” said the deputy, “answer me frankly, not as a prisoner to a\\n', 'judge, but as one man to another who takes an interest in him, what\\n', 'truth is there in the accusation contained in this anonymous letter?”\\n', 'And Villefort threw disdainfully on his desk the letter Dantès had just\\n', 'given back to him.\\n', '\\n', '“None at all. I will tell you the real facts. I swear by my honor as a\\n', 'sailor, by my love for Mercédès, by the life of my father——”\\n', '\\n', '“Speak, monsieur,” said Villefort. Then, internally, “If Renée could\\n', 'see me, I hope she would be satisfied, and would no longer call me a\\n', 'decapitator.”\\n']\n"
     ]
    }
   ],
   "source": [
    "# Lets look as a sample of file:\n",
    "\n",
    "with open(fname, encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "np.random.seed(1337)\n",
    "rand_line_num = np.random.randint(len(lines))\n",
    "\n",
    "print(lines[rand_line_num:rand_line_num+30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7dedb23-ca6c-4fd8-baae-81d6c35885fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes, that's some odd formating? so let's clean this up:\n",
    "\n",
    "def lines_to_paragraphs(lines):\n",
    "\n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    \n",
    "    for l in lines:\n",
    "        \n",
    "        l = l.strip()\n",
    "        if l:\n",
    "            buffer.append(l)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append((\" \").join(buffer))\n",
    "            buffer = []\n",
    "                    \n",
    "    if len(buffer):\n",
    "        paragraphs.append((\" \").join(buffer))\n",
    "\n",
    "    return paragraphs\n",
    "    \n",
    "\n",
    "paragraphs = lines_to_paragraphs(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9c4330-d471-4176-bb06-89e3593b6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“You are right; you know men better than I do, and what you say may possibly be the case, I confess; but if such persons are among my acquaintances I prefer not to know it, because then I should be forced to hate them.”\n",
      "[746]\n"
     ]
    }
   ],
   "source": [
    "# lets find the index of the text previously seen and get the new format\n",
    "\n",
    "paragraph_lines = []\n",
    "for i, p in enumerate(paragraphs):\n",
    "    if lines[rand_line_num].strip() in p:\n",
    "        paragraph_lines.append(i)\n",
    "\n",
    "for pl in paragraph_lines:\n",
    "    print(paragraphs[pl])\n",
    "\n",
    "print(paragraph_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "943a950f-a4b8-41aa-89b6-4b03a782dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving new embeedings to embeddings/tcomc_embeddings.npy...\n",
      "\t...done!\n"
     ]
    }
   ],
   "source": [
    "# Ok, now that the data looks better! Let's embed each paragraph using a pretrained model. \n",
    "# Since this may take awhile, lets be able save and load on demand once the embeddings are created.\n",
    "# For memory and time we will use npy objects.\n",
    "\n",
    "# One the first time, this may take awhile so grab a coffee.\n",
    "\n",
    "def load_embeddings(fname):\n",
    "\n",
    "    inpath = f\"embeddings/{fname}.npy\"\n",
    "    if not os.path.exists(f\"embeddings/{fname}.npy\"):\n",
    "        return False\n",
    "\n",
    "    print(f'Loading embeddings from {inpath}')\n",
    "    with open(f\"embeddings/{fname}.npy\", \"rb\") as f:\n",
    "        embeddings = np.load(f)\n",
    "    print(f'\\t...done!')\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def save_embeddings(embeddings, fname):\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    outpath = f\"embeddings/{fname}.npy\"\n",
    "\n",
    "    print(f'saving new embeedings to {outpath}...')\n",
    "    if not os.path.exists(\"embeddings\"):      \n",
    "        os.makedirs(\"embeddings\")\n",
    "  \n",
    "    with open(outpath, \"wb\") as f:\n",
    "        np.save(f, embeddings)\n",
    "    print(f'\\t...done!')\n",
    "\n",
    "\n",
    "def gen_paragrpah_embeddings(paragraphs, model_name, outname=None):\n",
    "    \n",
    "    if (embeddings := load_embeddings(outname)) is not False:\n",
    "        return embeddings\n",
    "    \n",
    "    embeddings = [ollama.embeddings(model=model_name, prompt=p)[\"embedding\"] for p in paragraphs]\n",
    "\n",
    "    if outname is not None:\n",
    "        save_embeddings(embeddings, outname)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = gen_paragrpah_embeddings(paragraphs, \"nomic-embed-text\", outname='tcomc_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f0ba29-5f3f-4ca9-a6a3-f742bd262072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to be able to find similar embeddings. For this we will use cosine similarity.\n",
    "# It is worth while writting this up in a vectorized way:\n",
    "\n",
    "def ranked_cosine_similarity(ref, embeddings):\n",
    "\n",
    "    ref = np.array(ref)\n",
    "    embeddings = np.array(embeddings).T\n",
    "    cos_similarities = ref.dot(embeddings)/(np.linalg.norm(ref)*np.linalg.norm(embeddings, axis=0))\n",
    "    return(np.argsort(cos_similarities)[::-1])\n",
    "\n",
    "cosine_sims_idx = ranked_cosine_similarity(np.array(embeddings[746]), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "734b6198-2d7e-4cd3-94d3-00e1374f9984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  746, 12739,  6104,  6086, 13831,  2674,  6091, 11459,  4854,\n",
       "        1933])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that it worked, we should see 746 as the first entry:\n",
    "\n",
    "cosine_sims_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e293dab8-b10f-40ef-bd97-8d73d7988964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“You are right; you know men better than I do, and what you say may possibly be the case, I confess; but if such persons are among my acquaintances I prefer not to know it, because then I should be forced to hate them.”\n",
      "“Hold your tongue! The men are all infamous, and I am happy to be able now to do more than detest them—I despise them.”\n",
      "“I know it sir,” replied Monte Cristo; “but when I visit a country I begin to study, by all the means which are available, the men from whom I may have anything to hope or to fear, till I know them as well as, perhaps better than, they know themselves. It follows from this, that the king’s attorney, be he who he may, with whom I should have to deal, would assuredly be more embarrassed than I should.”\n",
      "“Really, sir,” he observed, “I see that in spite of the reputation which you have acquired as a superior man, you look at everything from the material and vulgar view of society, beginning with man, and ending with man—that is to say, in the most restricted, most narrow view which it is possible for human understanding to embrace.”\n",
      "“Well, I should say! If you had me taken to a private room only to tell me this, you might have saved yourself the trouble. I know all these things. But there are some with which, on the contrary, I am not acquainted. Let us talk of those, if you please. Who sent you?”\n",
      "“You prefer, then,” said the abbé, “that I should bestow on men you say are false and treacherous, the reward intended for faithful friendship?”\n",
      "“Your pardon, sir,” replied Villefort, quite astounded, “but you will excuse me if, when I presented myself to you, I was unaware that I should meet with a person whose knowledge and understanding so far surpass the usual knowledge and understanding of men. It is not usual with us corrupted wretches of civilization to find gentlemen like yourself, possessors, as you are, of immense fortune—at least, so it is said—and I beg you to observe that I do not inquire, I merely repeat;—it is not usual, I say, for such privileged and wealthy beings to waste their time in speculations on the state of society, in philosophical reveries, intended at best to console those whom fate has disinherited from the goods of this world.”\n",
      "“I? Silence, purveyor of gossip, do not spread that report. I make a match? No, you do not know me; I have done all in my power to oppose it.”\n",
      "“But you do not know this man.”\n",
      "“You must teach me a small part of what you know,” said Dantès, “if only to prevent your growing weary of me. I can well believe that so learned a person as yourself would prefer absolute solitude to being tormented with the company of one as ignorant and uninformed as myself. If you will only agree to my request, I promise you never to mention another word about escaping.”\n"
     ]
    }
   ],
   "source": [
    "# Nice, let's see what else is similar\n",
    "\n",
    "for p_idx in cosine_sims_idx[:10]:\n",
    "    print(paragraphs[p_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179130ad-dbf7-424b-bf89-e3c2d78fac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool, getting there! No we write the final RAG function:\n",
    "\n",
    "RAG_PROMPT = '''\n",
    "You are a helpful reading assistant who answers questions \n",
    "based on snippets of text provided in context. Answer only using the context provided, \n",
    "being as concise as possible. If you're unsure, just say that you don't know.\n",
    "Context:'''\n",
    "\n",
    "def gen_RAG_prompt(context):\n",
    "\n",
    "    do_RAG = RAG_PROMPT.replace('\\n','')\n",
    "    \n",
    "    return f'{do_RAG}\\n{context}'\n",
    "    \n",
    "\n",
    "def do_RAG(question, embeddings, paragraphs, num_paragraphs=20):\n",
    "\n",
    "    prompt_embed = ollama.embeddings(model=\"nomic-embed-text\", prompt=question)['embedding']\n",
    "    similar_paragraph_idxs = ranked_cosine_similarity(prompt_embed, embeddings)\n",
    "    context = '\\n'.join(paragraphs[idx] for idx in similar_paragraph_idxs[:num_paragraphs])\n",
    "    RAG_prompt = gen_RAG_prompt(context)\n",
    "    #print(RAG_prompt)\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model = 'mistral',\n",
    "        messages = [{'role': 'system',\n",
    "                     'content': RAG_prompt},\n",
    "                    {\"role\": \"user\", \n",
    "                     \"content\": question}\n",
    "                   ]\n",
    "        )\n",
    "    return response[\"message\"][\"content\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3849b8ab-6f30-4d24-803e-d2fd8f01bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How long was Dantes in jail?\n",
      "A:  Dantès had been imprisoned for seventeen months in the Château d'If. However, during his time in prison, he had lost track of the passage of time and could not recall exactly how long he had been there when he was brought before the magistrate for a trial. The magistrate, Caderousse, was skeptical of Dantès' story and wanted to know why he had been imprisoned. Dantès recounted his past, from his last voyage as a sailor to his arrest and imprisonment. After finishing his story, Dantès pleaded with Caderousse for a trial, but the magistrate remained unconvinced and left him in the care of another prisoner. The passage suggests that time had passed slowly for Dantès in prison, as he had spent ten months and a half in his cell before being brought before the magistrate.\n"
     ]
    }
   ],
   "source": [
    "# Ok, now lets test it out:\n",
    "\n",
    "question = 'How long was Dantes in jail?'\n",
    "response = do_RAG(question, embeddings, paragraphs)\n",
    "\n",
    "print(f'Q: {question}')\n",
    "print(f'A: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253dc5a9-a2b0-4dc2-9877-b4110b416dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
